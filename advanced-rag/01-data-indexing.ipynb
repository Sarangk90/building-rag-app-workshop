{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f2244f11eab922",
   "metadata": {},
   "source": [
    "# Data indexing\n",
    "\n",
    "## Scifact Dataset\n",
    "\n",
    "\n",
    "The Scifact dataset is a specialized collection of scientific claims and evidence from research papers, designed for scientific fact-checking and verification tasks. It consists of scientific claims paired with abstracts from research papers that either support or refute these claims.\n",
    "\n",
    "The dataset contains over 5,000 scientific abstracts from research papers across various scientific domains including medicine, biology, chemistry, and other life sciences. Each entry in the dataset includes a unique ID, the paper's title, and the full text of the abstract.\n",
    "\n",
    "Originally created to help evaluate scientific claim verification systems, this dataset is part of the Benchmark for Scientific Claim Verification (BeIR) collection. It's particularly useful for building scientific fact-checking systems, training models to understand and verify scientific claims, and developing information retrieval systems for scientific literature.\n",
    "\n",
    "Let's explore the dataset structure and prepare it for our RAG application.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d321e6755b15e1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T05:13:01.272670Z",
     "start_time": "2025-02-08T05:12:47.882895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'_id': '4983',\n 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.',\n 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"BeIR/scifact\", \"corpus\", split=\"corpus\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26797f7a57adc4ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T05:13:01.280400Z",
     "start_time": "2025-02-08T05:13:01.275412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "5183"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976c453bf0d27c0",
   "metadata": {},
   "source": [
    "## Dense embeddings\n",
    "\n",
    "We're not going to choose the fanciest embedding model out there, but stick to something simple and efficient. FastEmbed comes with some pretrained models that we can use out of the box. Due to ONNX usage, these models can be launched efficiently even on a CPU. The `all-MiniLM-L6-v2` model is a lightweight model that's good for a start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611ad98114d793b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T05:13:08.349599Z",
     "start_time": "2025-02-08T05:13:01.282252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca09a8337034454f963558e183e4adce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a51fc241d82a4e649fae7a95f1d4c0de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d7ae3505fae48f8a816ff843568b35f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11b99b4583ec4e90b4749170dae0f844"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e328ab4fed3c4f3db112dfcd1247b944"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45d6698a6d66419987e929647c628b5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "dense_embedding_model = TextEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "dense_embeddings = list(dense_embedding_model.passage_embed(dataset[\"text\"][0:1]))\n",
    "len(dense_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702cbdb3d2c6a32a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T05:13:08.357281Z",
     "start_time": "2025-02-08T05:13:08.351648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "384"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dense_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74386f75bb96941",
   "metadata": {},
   "source": [
    "## Sparse embeddings\n",
    "\n",
    "Similarly, we can use a BM25 model to generate sparse embeddings, so it hopefully will handle the cases in which the dense embeddings fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70bc60aa2d0956d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T05:13:13.768417Z",
     "start_time": "2025-02-08T05:13:08.362035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3393cd134734721b94335d67af582ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "danish.txt:   0%|          | 0.00/424 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebee638c75ec497a825d702365b3c1f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "arabic.txt:   0%|          | 0.00/6.35k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4bae5ad92625451ea419de7db34460a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "basque.txt:   0%|          | 0.00/2.20k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38b50c294b584ed3bcf5fc3c35e89c5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "bengali.txt:   0%|          | 0.00/5.44k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc60b669ee0644feb8ffd94e778e8847"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "azerbaijani.txt:   0%|          | 0.00/967 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08ab7dc6bf504ddd827d026ebd151ddd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "catalan.txt:   0%|          | 0.00/1.56k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4ef1841f9ed4eacaa380bb8a977ae36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "dutch.txt:   0%|          | 0.00/453 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "011d5eda1bd446f48ae6a0519a0a862c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "chinese.txt:   0%|          | 0.00/5.56k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "225099410b804336b7252e94551b285e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "517f84dd7c5a48868a7afd67b0539590"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "french.txt:   0%|          | 0.00/813 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de6e575d173f4b3cae4ed1fa2e38e447"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "finnish.txt:   0%|          | 0.00/1.58k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8529efb38d3a444c93d6aae6765464c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "hebrew.txt:   0%|          | 0.00/1.84k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05fc46b859ed45c3a449c966443b3573"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "english.txt:   0%|          | 0.00/936 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71ee7a1b349248868f2e25ff1b7aac89"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "german.txt:   0%|          | 0.00/1.36k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70f4e85aca4c4915838aec29d2be73fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "greek.txt:   0%|          | 0.00/2.17k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36f5399e64844eaca76e0f135800cf1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "indonesian.txt:   0%|          | 0.00/6.45k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1c0f2664ea4490e94c0ee403e9a51fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "hinglish.txt:   0%|          | 0.00/5.96k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71868fccf82447a79519dd1f419e5024"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "nepali.txt:   0%|          | 0.00/3.61k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7225a29f79954b2ab71627d7e480a7ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "norwegian.txt:   0%|          | 0.00/851 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1e469d886234fe4ba859738297e85be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "italian.txt:   0%|          | 0.00/1.65k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0783ec8e1b114a6c8e572c722c609d24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "hungarian.txt:   0%|          | 0.00/1.23k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a7b34450d144bbeba577c350765c0cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "kazakh.txt:   0%|          | 0.00/3.88k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8553158951f7483b843632b004fd79e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "portuguese.txt:   0%|          | 0.00/1.29k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6df0591cc4d244fc8051242a6efc5a73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spanish.txt:   0%|          | 0.00/2.18k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9e1cf9775f9462794443d38d5187b10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "russian.txt:   0%|          | 0.00/1.24k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f45a0d7a7f57452ba9829da0b97a9ab4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "slovene.txt:   0%|          | 0.00/16.0k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83fb736103624acc98c7ce114dec747f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "swedish.txt:   0%|          | 0.00/559 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a395af9ce434f619b53d165a5f587b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "turkish.txt:   0%|          | 0.00/260 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5411b8e241e343d399158d55b7d610c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tajik.txt:   0%|          | 0.00/1.82k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9dbe993e81e45d2a8b9b0cafd50bfac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "romanian.txt:   0%|          | 0.00/1.91k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed51255904b54f299fb068cc5b1b855c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "[SparseEmbedding(values=array([1.05924393, 1.42998604, 1.73332307, 1.96487964, 1.96487964,\n        1.73332307, 1.05924393, 1.05924393, 1.05924393, 1.05924393,\n        1.05924393, 1.05924393, 1.05924393, 1.05924393, 1.05924393,\n        1.96487964, 1.05924393, 1.05924393, 1.05924393, 1.05924393,\n        1.61885599, 1.05924393, 1.61885599, 1.05924393, 1.05924393,\n        1.05924393, 1.61885599, 1.73332307, 1.05924393, 1.61885599,\n        1.61885599, 1.05924393, 1.05924393, 1.05924393, 1.61885599,\n        1.73332307, 1.61885599, 1.05924393, 1.61885599, 1.93897663,\n        1.86520947, 1.05924393, 1.42998604, 1.05924393, 1.05924393,\n        1.42998604, 1.05924393, 1.42998604, 1.05924393, 1.05924393,\n        1.42998604, 1.61885599, 1.61885599, 1.42998604, 1.42998604,\n        1.05924393, 1.93897663, 1.05924393, 1.73332307, 1.73332307,\n        1.05924393, 1.05924393, 1.42998604, 1.05924393, 1.05924393,\n        1.61885599, 1.61885599, 1.05924393, 1.73332307, 1.42998604,\n        1.05924393, 1.05924393, 1.05924393, 1.05924393, 1.05924393,\n        1.42998604, 1.42998604, 1.96487964, 1.42998604, 1.05924393,\n        1.05924393, 1.61885599, 1.05924393, 1.05924393, 1.05924393,\n        1.05924393, 1.42998604, 1.42998604, 1.05924393, 1.05924393,\n        1.05924393, 1.05924393, 1.05924393, 1.05924393, 1.05924393,\n        1.05924393, 1.05924393, 1.05924393, 1.05924393, 1.05924393,\n        1.05924393, 1.05924393, 1.05924393, 1.05924393, 1.05924393,\n        1.05924393, 1.05924393, 1.05924393, 1.05924393]), indices=array([ 354307472,  794129062,  242156862,  611385325,  581432272,\n         659326392, 1082468256,  512480045,  194714415, 1001081408,\n         442064690, 1031134330,  880670268,  640477688,  756007634,\n        1093482543,  555641829, 1162692215, 1960942172,  301030427,\n         104660491, 1727802518, 1595981574, 1298296063,  804460016,\n        1365144653, 1923685331, 1376624736, 1230423685, 1338150097,\n         640186380,  160759034, 1296924235, 1701701189,   64890871,\n         915998194,  967714644, 1852771076, 1058501323,  754797265,\n         440354553,  602572328,  119240421,  243669559, 1326575350,\n        1724426273,  291984105, 2031875777,  150760872,  436751995,\n        2058513491,  588610688,  832098838, 2112545234,  600196326,\n        1612531086, 1810453357, 1114505193, 1557248238,  909343648,\n         525896179,  719013046,   19522071, 1050957324,  105575576,\n        2139336747, 1748573614, 1060439614, 1475834753,  732777880,\n        2008886724, 2039278182, 1207805233,  967537333, 1289414591,\n         570652574,  516830072,  764297089, 2075059736,  697303812,\n         140061020, 1737498726, 2085101493, 1559397529, 1214902428,\n        1661675969,  613148321,  670727360,  312050228,  264741300,\n        1577650016,  395514983, 1265401351,  872547724, 1347729265,\n        1330873646, 2081365401, 1664960354, 1552499548,  327797310,\n         957769532,  989116115, 1563317370,  518587678,  918197339,\n        1563718956,  614665414, 1906054390,  123462699]))]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed import SparseTextEmbedding\n",
    "\n",
    "bm25_embedding_model = SparseTextEmbedding(\"Qdrant/bm25\")\n",
    "bm25_embeddings = list(bm25_embedding_model.passage_embed(dataset[\"text\"][0:1]))\n",
    "bm25_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4fbac945e35a55",
   "metadata": {},
   "source": [
    "## Putting data in a Qdrant collection\n",
    "\n",
    "All the vectors might be now upserted into a Qdrant collection. Keeping them all in a single one enables the possibility to combine different embeddings and create even a complex pipeline with several steps. Depending on the specifics of your data, you may prefer to use a different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431ec613-ad0c-4a35-b0da-bb2f69294999",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T05:13:14.599810Z",
     "start_time": "2025-02-08T05:13:13.770259Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e6b97b1f531354e484223a2d0c6010df090c7e3b01d7a440f22fe9d70452ae8\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -d -p 6333:6333 -p 6334:6334 qdrant/qdrant:v1.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f0ba5b8b767ae5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T05:13:16.180023Z",
     "start_time": "2025-02-08T05:13:14.601694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/zrcd72dj2kgb044vzkyfzgz40000gn/T/ipykernel_4321/2639802772.py:3: UserWarning: Qdrant client version 1.13.2 is incompatible with server version 1.10.0. Major versions should match and minor version difference must not exceed 1. Set check_version=False to skip version check.\n",
      "  client = QdrantClient(\"http://localhost:6333\", timeout=600)\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\", timeout=600)\n",
    "client.create_collection(\n",
    "    \"scifact\",\n",
    "    vectors_config={\n",
    "        \"all-MiniLM-L6-v2\": models.VectorParams(\n",
    "            size=len(dense_embeddings[0]),\n",
    "            distance=models.Distance.COSINE,\n",
    "        )\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "238650e7e3ea136e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-02-08T05:14:41.003038Z",
     "start_time": "2025-02-08T05:13:16.181342Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1037it [01:24, 12.23it/s]                          \n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "batch_size = 5\n",
    "for batch in tqdm.tqdm(dataset.iter(batch_size=batch_size), \n",
    "                       total=len(dataset) // batch_size):\n",
    "    dense_embeddings = list(dense_embedding_model.passage_embed(batch[\"text\"]))\n",
    "    bm25_embeddings = list(bm25_embedding_model.passage_embed(batch[\"text\"]))\n",
    "    \n",
    "    client.upload_points(\n",
    "        \"scifact\",\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=int(batch[\"_id\"][i]),\n",
    "                vector={\n",
    "                    \"all-MiniLM-L6-v2\": dense_embeddings[i].tolist(),\n",
    "                    \"bm25\": bm25_embeddings[i].as_object(),\n",
    "                },\n",
    "                payload={\n",
    "                    \"_id\": batch[\"_id\"][i],\n",
    "                    \"title\": batch[\"title\"][i],\n",
    "                    \"text\": batch[\"text\"][i],\n",
    "                }\n",
    "            )\n",
    "            for i, _ in enumerate(batch[\"_id\"])\n",
    "        ],\n",
    "        # We send a lot of embeddings at once, so it's best to reduce the batch size.\n",
    "        # Otherwise, we would have gigantic requests sent for each batch and we can\n",
    "        # easily reach the maximum size of a single request.\n",
    "        batch_size=batch_size,  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae256b5-b874-41e4-b633-85c16f29f2c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T05:14:41.008134Z",
     "start_time": "2025-02-08T05:14:41.005320Z"
    }
   },
   "outputs": [],
   "source": [
    "# client.recover_snapshot(\n",
    "#     \"scifact\",\n",
    "#     location=\"https://storage.googleapis.com/common-datasets-snapshots/scifact-multiple-representations.snapshot\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d8154fe8e865a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T05:14:41.032352Z",
     "start_time": "2025-02-08T05:14:41.010771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=None, indexed_vectors_count=5183, points_count=5183, segments_count=6, config=CollectionConfig(params=CollectionParams(vectors={'all-MiniLM-L6-v2': VectorParams(size=384, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None)}, shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors={'bm25': SparseVectorParams(index=None, modifier=<Modifier.IDF: 'idf'>)}), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None, strict_mode_config=None), payload_schema={})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collection(\"scifact\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
