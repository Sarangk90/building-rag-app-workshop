{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Setup Prerequisites\n",
    "\n",
    "## üîó Complete Setup Required\n",
    "\n",
    "Before running this notebook, you **must** complete the workshop setup process:\n",
    "\n",
    "üìñ **Please follow the complete setup guide here: [`SETUP.md`](../SETUP.md)**\n",
    "\n",
    "This notebook requires:\n",
    "- ‚úÖ **Qdrant database** setup (Cloud or Docker)\n",
    "- ‚úÖ **Data ingestion** completed \n",
    "- ‚úÖ **OPENAI_API_KEY** configured\n",
    "- ‚úÖ **COHERE_API_KEY** configured (for reranking features)\n",
    "\n",
    "**üö´ Do not proceed** until setup is complete!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Workshop Notebook - Naive RAG with Cohere Reranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T06:33:55.452787Z",
     "start_time": "2025-07-18T06:33:55.446366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T06:33:59.107388Z",
     "start_time": "2025-07-18T06:33:57.418997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Qdrant Cloud\n",
      "üìö Collection: workshop_wikipedia_extended\n",
      "ü§ñ Embedding model: text-embedding-3-small\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# Initialize Qdrant Cloud client\n",
    "qdrant_client = QdrantClient(\n",
    "    url=os.getenv(\"QDRANT_URL\"),\n",
    "    api_key=os.getenv(\"QDRANT_API_KEY\")\n",
    ")\n",
    "\n",
    "# Collection configuration\n",
    "collection_name = \"workshop_wikipedia_extended\"\n",
    "embedding_model = \"text-embedding-3-small\"\n",
    "\n",
    "print(f\"‚úÖ Connected to Qdrant Cloud\")\n",
    "print(f\"üìö Collection: {collection_name}\")\n",
    "print(f\"ü§ñ Embedding model: {embedding_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Verify Collection and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T06:34:43.515907Z",
     "start_time": "2025-07-18T06:34:42.885169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Collection Statistics:\n",
      "   Total chunks: 1,210\n",
      "   Vector dimension: 1536\n",
      "   Distance metric: Cosine\n",
      "\n",
      "üìù Sample data structure:\n",
      "\n",
      "Chunk 1:\n",
      "   Title: BERT (language model)\n",
      "   Text preview: Bidirectional encoder representations from transformers (BERT) is a language model introduced in Oct...\n",
      "   Chunk 1 of 10\n",
      "\n",
      "Chunk 2:\n",
      "   Title: BERT (language model)\n",
      "   Text preview: Euclidean space. Encoder: a stack of Transformer blocks with self-attention, but without causal mask...\n",
      "   Chunk 2 of 10\n",
      "\n",
      "Chunk 3:\n",
      "   Title: BERT (language model)\n",
      "   Text preview: consists of a sinusoidal function that takes the position in the sequence as input. Segment type: Us...\n",
      "   Chunk 3 of 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get collection information\n",
    "collection_info = qdrant_client.get_collection(collection_name)\n",
    "point_count = collection_info.points_count\n",
    "\n",
    "print(f\"üìä Collection Statistics:\")\n",
    "print(f\"   Total chunks: {point_count:,}\")\n",
    "print(f\"   Vector dimension: {collection_info.config.params.vectors.size}\")\n",
    "print(f\"   Distance metric: {collection_info.config.params.vectors.distance}\")\n",
    "\n",
    "# Sample a few points to see the data structure\n",
    "sample_points = qdrant_client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    limit=3,\n",
    "    with_payload=True,\n",
    "    with_vectors=False\n",
    ")[0]\n",
    "\n",
    "print(f\"\\nüìù Sample data structure:\")\n",
    "for i, point in enumerate(sample_points):\n",
    "    payload = point.payload\n",
    "    print(f\"\\nChunk {i+1}:\")\n",
    "    print(f\"   Title: {payload.get('title', 'Unknown')}\")\n",
    "    print(f\"   Text preview: {payload.get('text', '')[:100]}...\")\n",
    "    print(f\"   Chunk {payload.get('chunk_index', 0)+1} of {payload.get('total_chunks', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Q/A Chatbot\n",
    "\n",
    "![../imgs/naive-rag.png](../imgs/naive-rag.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Retrieval - Search the database for the most relevant embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk_index': 0,\n",
      " 'text': 'In machine learning, deep learning focuses on utilizing multilayered '\n",
      "         'neural networks to perform tasks such as classification, regression, '\n",
      "         'and representation learning. The field takes inspiration from '\n",
      "         'biological neuroscience and is centered around stacking artificial '\n",
      "         'neurons into layers and \"training\" them to process data. The '\n",
      "         'adjective \"deep\" refers to the use of multiple layers (ranging from '\n",
      "         'three to several hundred or thousands) in the network. Methods used '\n",
      "         'can be supervised, semi-supervised or unsupervised. Some common deep '\n",
      "         'learning network architectures include fully connected networks, '\n",
      "         'deep belief networks, recurrent neural networks, convolutional '\n",
      "         'neural networks, generative adversarial networks, transformers, and '\n",
      "         'neural radiance fields. These architectures have been applied to '\n",
      "         'fields including computer vision, speech recognition, natural '\n",
      "         'language processing, machine translation, bioinformatics, drug '\n",
      "         'design, medical image analysis, climate science, material inspection '\n",
      "         'and board game programs, where they have produced results comparable '\n",
      "         'to and in some cases surpassing human expert performance. Early '\n",
      "         'forms of neural networks were inspired by information processing and '\n",
      "         'distributed communication nodes in biological systems, particularly '\n",
      "         'the human brain. However, current neural networks do not intend to '\n",
      "         'model the brain function of organisms, and are generally seen as '\n",
      "         'low-quality models for that purpose. Overview Most modern deep '\n",
      "         'learning models are based on multi-layered neural networks such as '\n",
      "         'convolutional neural networks and transformers, although they can '\n",
      "         'also include propositional formulas or latent variables organized '\n",
      "         'layer-wise in deep generative models such as the nodes in deep '\n",
      "         'belief networks and deep Boltzmann machines. Fundamentally, deep '\n",
      "         'learning refers to a class of machine learning algorithms in which a '\n",
      "         'hierarchy of layers is used to transform input data into a '\n",
      "         'progressively more abstract and composite representation. For '\n",
      "         'example, in an image recognition model, the raw input may be an '\n",
      "         'image (represented as a tensor of pixels). The first '\n",
      "         'representational layer may attempt to identify basic shapes such as',\n",
      " 'title': 'Deep learning',\n",
      " 'total_chunks': 34,\n",
      " 'url': 'https://en.wikipedia.org/wiki/Deep_learning'}\n"
     ]
    }
   ],
   "source": [
    "# Function to search the database\n",
    "def vector_search(query, top_k=1):\n",
    "    # create embedding of the query\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    query_embeddings = response.data[0].embedding\n",
    "    # similarity search using the embedding, give top n results which are close to the query embeddings\n",
    "    search_result = qdrant_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_embeddings,\n",
    "        with_payload=True,\n",
    "        limit=top_k,\n",
    "    ).points\n",
    "    return [result.payload for result in search_result]\n",
    "\n",
    "\n",
    "search_result = vector_search(\"What does the word 'deep' in 'deep learning' refer\")\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(search_result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Generation - Use the retrieved embeddings to generate the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generate(prompt, model=\"gpt-4o\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def prompt_template(question, context):\n",
    "    return \"\"\"You are a AI Assistant that provides answer to the question at the end, over the following\n",
    "  pieces of context. Make sure to only use the context to answer the question. Keep the wording very close to the context.\n",
    "  Explicitly mention you DONT KNOW if the answer is not in the context. Answering questions when the answers are not in the context is NOT allowed.\n",
    "  context:\n",
    "  ```\n",
    "  \"\"\" + json.dumps(context) + \"\"\"\n",
    "  ```\n",
    "  User question: \"\"\" + question + \"\"\"\n",
    "  Answer in markdown:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    #Retrieval: search a knowledge base.\n",
    "    search_result = vector_search(question)\n",
    "\n",
    "    prompt = prompt_template(question, search_result)\n",
    "    # Generation: LLMs' ability to generate the answer\n",
    "    return model_generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ```markdown\n",
      "The time delay neural network (TDNN) was introduced in 1987 by Alex Waibel.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "question = f\"Who introduced the time delay neural network (TDNN)? and when ?\"\n",
    "answer = generate_answer(question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RAG Evaluation with RAGAS\n",
    "\n",
    "Before proceeding with improvements, let's establish baseline scores using **RAGAS** (Retrieval Augmented Generation Assessment Suite) - a specialized framework designed specifically for evaluating RAG systems.\n",
    "\n",
    "### Context-Focused Metrics:\n",
    "\n",
    "1. **Context Precision**: How well are relevant chunks ranked at the top?\n",
    "2. **Context Recall**: How much of the necessary information was retrieved?\n",
    "3. **Context Relevancy**: How relevant is the retrieved context to the question?\n",
    "\n",
    "We're using **RAGAS** because it's purpose-built for RAG evaluation and provides deep insights into context quality - the most critical component of RAG performance. The evaluation is simple to use - just call one function!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating your Naive RAG system with RAGAS...\n",
      "This will evaluate context quality metrics on 15 questions...\n",
      "\n",
      "‚úÖ Loaded 14 questions from evaluation dataset\n",
      "\n",
      "Evaluating 14 questions...\n",
      "\n",
      "Question 1/14: Who introduced the ReLU (rectified linear unit) ac...\n",
      "Question 2/14: What was the first working deep learning algorithm...\n",
      "Question 3/14: Which CNN achieved superhuman performance in a vis...\n",
      "Question 4/14: When was BERT introduced and by which organization...\n",
      "Question 5/14: What are the two model sizes BERT was originally i...\n",
      "Question 6/14: What percentage of tokens are randomly selected fo...\n",
      "Question 7/14: Who introduced the term 'deep learning' to the mac...\n",
      "Question 8/14: Which three researchers were awarded the 2018 Turi...\n",
      "Question 9/14: When was the first GPT introduced and by which org...\n",
      "Question 10/14: What were the three parameter sizes of the first v...\n",
      "Question 11/14: What is the 'one in ten rule' in regression analys...\n",
      "Question 12/14: What is the essence of overfitting according to th...\n",
      "Question 13/14: In which year and paper was the modern version of ...\n",
      "Question 14/14: What value did the original Transformer paper use ...\n",
      "\n",
      "üîç Running RAGAS evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313dd234cc384bbbb4319eac8fa9f4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAGAS EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "üìã INDIVIDUAL QUESTION SCORES:\n",
      "------------------------------------------------------------\n",
      " 1. üü¢ 1.000 - Who introduced the ReLU (rectified linear unit) activation f...\n",
      " 2. üî¥ 0.000 - What was the first working deep learning algorithm and who p...\n",
      " 3. üü¢ 1.000 - Which CNN achieved superhuman performance in a visual patter...\n",
      " 4. üî¥ 0.000 - When was BERT introduced and by which organization?\n",
      " 5. üü¢ 1.000 - What are the two model sizes BERT was originally implemented...\n",
      " 6. üü¢ 1.000 - What percentage of tokens are randomly selected for the mask...\n",
      " 7. üî¥ 0.000 - Who introduced the term 'deep learning' to the machine learn...\n",
      " 8. üî¥ 0.000 - Which three researchers were awarded the 2018 Turing Award f...\n",
      " 9. üü¢ 1.000 - When was the first GPT introduced and by which organization?\n",
      "10. üü¢ 1.000 - What were the three parameter sizes of the first versions of...\n",
      "11. üü¢ 1.000 - What is the 'one in ten rule' in regression analysis?\n",
      "12. üü¢ 1.000 - What is the essence of overfitting according to the article?\n",
      "13. üü¢ 1.000 - In which year and paper was the modern version of the transf...\n",
      "14. üü¢ 1.000 - What value did the original Transformer paper use for the pa...\n",
      "\n",
      "============================================================\n",
      "üìä AGGREGATE RESULTS\n",
      "============================================================\n",
      "\n",
      "CONTEXT RECALL METRIC (0.0 - 1.0 scale):\n",
      "  üü° Context Recall: 0.714\n",
      "============================================================\n",
      "\n",
      "üí° Tip: Add show_detailed=True to see full question details\n"
     ]
    }
   ],
   "source": [
    "# Import the RAGAS evaluation utility\n",
    "# Import the RAGAS evaluation utility\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../naive-rag')\n",
    "from rag_evaluator_v2 import evaluate_naive_rag_v2\n",
    "\n",
    "# Run evaluation on the current RAG system using RAGAS\n",
    "print(\"üîç Evaluating your Naive RAG system with RAGAS...\")\n",
    "print(\"This will evaluate context quality metrics on 14 questions...\\n\")\n",
    "\n",
    "baseline_results = evaluate_naive_rag_v2(\n",
    "    vector_search_func=vector_search,\n",
    "    generate_answer_func=generate_answer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä BASELINE CONTEXT METRICS SUMMARY:\n",
      "Context Recall: 0.714\n",
      "\n",
      "üí° What these RAGAS metrics mean:\n",
      "‚Ä¢ Context Recall: How much of the necessary information was retrieved\n",
      "\n",
      "üéØ Score Interpretation:\n",
      "‚Ä¢ 0.8+ = Excellent\n",
      "‚Ä¢ 0.6-0.8 = Good\n",
      "‚Ä¢ 0.4-0.6 = Needs Improvement\n",
      "‚Ä¢ <0.4 = Poor\n"
     ]
    }
   ],
   "source": [
    "# Store baseline scores for comparison later\n",
    "baseline_scores = baseline_results.get('aggregate_scores', {})\n",
    "\n",
    "print(\"üìä BASELINE CONTEXT METRICS SUMMARY:\")\n",
    "if 'context_recall' in baseline_scores:\n",
    "    print(f\"Context Recall: {baseline_scores['context_recall']:.3f}\")\n",
    "\n",
    "print(\"\\nüí° What these RAGAS metrics mean:\")\n",
    "print(\"‚Ä¢ Context Recall: How much of the necessary information was retrieved\")\n",
    "\n",
    "print(\"\\nüéØ Score Interpretation:\")\n",
    "print(\"‚Ä¢ 0.8+ = Excellent\")\n",
    "print(\"‚Ä¢ 0.6-0.8 = Good\") \n",
    "print(\"‚Ä¢ 0.4-0.6 = Needs Improvement\")\n",
    "print(\"‚Ä¢ <0.4 = Poor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìã Why We Need These Baseline Scores\n",
    "\n",
    "These **RAGAS-powered** baseline scores are crucial because:\n",
    "\n",
    "1. **Context Quality Focus**: RAGAS specifically measures how well your retrieval system finds and ranks relevant information\n",
    "2. **Purpose-Built for RAG**: Unlike general evaluation tools, RAGAS is designed specifically for RAG systems\n",
    "3. **Objective Measurement**: Quantitative metrics that measure actual retrieval performance\n",
    "4. **Debugging Aid**: Low context scores immediately tell you where your RAG is failing\n",
    "5. **Optimization Guide**: Use these metrics to systematically improve your retrieval strategy\n",
    "\n",
    "üî¨ **What makes RAGAS special**: \n",
    "- **Context Precision** helps ensure the most relevant information appears first\n",
    "- **Context Recall** ensures you're not missing important information\n",
    "- **Context Relevancy** validates that retrieved chunks actually help answer the question\n",
    "\n",
    "**Next Steps**: Now that we have our baseline context metrics, let's improve our RAG system with Cohere's reranking!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Improving RAG with Cohere Reranking\n",
    "\n",
    "Now let's see how adding a reranking step can improve our context selection and overall RAG performance.\n",
    "\n",
    "### Why Reranking?\n",
    "\n",
    "While vector similarity search is good at finding semantically related content, it has limitations:\n",
    "- **Bi-encoder limitation**: Vector embeddings compress all information into a fixed-size representation\n",
    "- **Lost nuances**: Subtle relevance signals can be lost in the embedding process\n",
    "- **No query-document interaction**: Embeddings are created independently\n",
    "\n",
    "Reranking solves these issues by:\n",
    "- **Cross-encoder architecture**: Processes query and document together\n",
    "- **Fine-grained relevance**: Captures subtle semantic relationships\n",
    "- **Better precision**: Filters out less relevant results even if they have high vector similarity\n",
    "\n",
    "### 4.1. Initialize Cohere Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cohere client initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "import os\n",
    "\n",
    "# Initialize Cohere client\n",
    "cohere_client = cohere.Client(os.getenv(\"COHERE_API_KEY\"))\n",
    "\n",
    "print(\"‚úÖ Cohere client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Simple Reranking Demo\n",
    "\n",
    "Before diving into the full RAG implementation, let's see a **simple example** of how Cohere reranking works:\n",
    "\n",
    "**The Challenge**: You have 10 documents about meditation, but only some directly answer \"health benefits\"\n",
    "\n",
    "**The Solution**: Cohere's rerank model can identify which documents are most relevant to your specific query\n",
    "\n",
    "This example will show:\n",
    "- üìù **Input**: A query + 10 documents (mixed relevance)\n",
    "- üß† **Processing**: Cohere rerank model scores each document\n",
    "- üèÜ **Output**: Top 3 most relevant documents with scores\n",
    "\n",
    "**Key Insight**: Notice how the reranker identifies documents that specifically mention health benefits (stress, blood pressure, heart disease) rather than just general meditation topics!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: What are the health benefits of meditation?\n",
      "\n",
      "üìö Documents to rank (10 total):\n",
      "1. Several clinical studies have shown that regular meditation can help reduce stress and anxiety levels.\n",
      "2. Meditation involves focusing the mind and eliminating distractions, often through breathing techniques or guided imagery.\n",
      "3. A daily meditation practice has been associated with lower blood pressure and improved sleep quality in adults.\n",
      "4. The city of Kyoto is famous for its Zen temples, where meditation has been practiced for centuries.\n",
      "5. People who meditate frequently often report feeling calmer and more focused throughout the day.\n",
      "6. Research suggests meditation may lower the risk of heart disease by reducing inflammation and improving heart rate variability.\n",
      "7. Meditation apps have become increasingly popular, offering guided sessions on mindfulness and relaxation.\n",
      "8. A 2021 meta-analysis found that meditation can reduce symptoms of depression when used alongside other treatments.\n",
      "9. Some forms of meditation emphasize compassion and kindness, aiming to improve emotional well-being.\n",
      "10. Athletes sometimes use meditation techniques to enhance concentration and mental resilience during competition.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üèÜ TOP 3 RERANKED RESULTS:\n",
      "(Notice how the reranker identifies the most health-focused documents!)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ü•á Rank #1\n",
      "   üìä Relevance Score: 0.9802\n",
      "   üìù Original Position: #6\n",
      "   üìÑ Text: Research suggests meditation may lower the risk of heart disease by reducing inflammation and improving heart rate variability.\n",
      "\n",
      "ü•á Rank #2\n",
      "   üìä Relevance Score: 0.9461\n",
      "   üìù Original Position: #3\n",
      "   üìÑ Text: A daily meditation practice has been associated with lower blood pressure and improved sleep quality in adults.\n",
      "\n",
      "ü•á Rank #3\n",
      "   üìä Relevance Score: 0.9315\n",
      "   üìù Original Position: #1\n",
      "   üìÑ Text: Several clinical studies have shown that regular meditation can help reduce stress and anxiety levels.\n",
      "\n",
      "================================================================================\n",
      "üí° Key Insight: Notice how documents specifically about health benefits\n",
      "   (stress reduction, blood pressure, heart disease) rank highest!\n"
     ]
    }
   ],
   "source": [
    "# üéØ Simple Reranking Example: See how Cohere rerank works!\n",
    "\n",
    "query = \"What are the health benefits of meditation?\"\n",
    "\n",
    "# Sample documents - some are highly relevant to health benefits, others less so\n",
    "documents = [\n",
    "    \"Several clinical studies have shown that regular meditation can help reduce stress and anxiety levels.\",\n",
    "    \"Meditation involves focusing the mind and eliminating distractions, often through breathing techniques or guided imagery.\",\n",
    "    \"A daily meditation practice has been associated with lower blood pressure and improved sleep quality in adults.\",\n",
    "    \"The city of Kyoto is famous for its Zen temples, where meditation has been practiced for centuries.\",\n",
    "    \"People who meditate frequently often report feeling calmer and more focused throughout the day.\",\n",
    "    \"Research suggests meditation may lower the risk of heart disease by reducing inflammation and improving heart rate variability.\",\n",
    "    \"Meditation apps have become increasingly popular, offering guided sessions on mindfulness and relaxation.\",\n",
    "    \"A 2021 meta-analysis found that meditation can reduce symptoms of depression when used alongside other treatments.\",\n",
    "    \"Some forms of meditation emphasize compassion and kindness, aiming to improve emotional well-being.\",\n",
    "    \"Athletes sometimes use meditation techniques to enhance concentration and mental resilience during competition.\",\n",
    "]\n",
    "\n",
    "print(\"üîç Query:\", query)\n",
    "print(\"\\nüìö Documents to rank (10 total):\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"{i+1}. {doc}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Use Cohere's rerank API directly\n",
    "try:\n",
    "    rerank_response = cohere_client.rerank(\n",
    "        query=query,\n",
    "        documents=documents,\n",
    "        model='rerank-english-v3.0',\n",
    "        top_n=3  # Get top 3 most relevant\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüèÜ TOP 3 RERANKED RESULTS:\")\n",
    "    print(\"(Notice how the reranker identifies the most health-focused documents!)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, result in enumerate(rerank_response.results):\n",
    "        doc_index = result.index + 1  # +1 for human-readable numbering\n",
    "        relevance_score = result.relevance_score\n",
    "        document_text = documents[result.index]\n",
    "        \n",
    "        print(f\"\\nü•á Rank #{i+1}\")\n",
    "        print(f\"   üìä Relevance Score: {relevance_score:.4f}\")\n",
    "        print(f\"   üìù Original Position: #{doc_index}\")\n",
    "        print(f\"   üìÑ Text: {document_text}\")\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üí° Key Insight: Notice how documents specifically about health benefits\")\n",
    "    print(\"   (stress reduction, blood pressure, heart disease) rank highest!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during reranking: {str(e)}\")\n",
    "    print(\"‚ö†Ô∏è  Make sure you have set COHERE_API_KEY in your environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Create Reranking Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_results(query, search_results, top_k=3, max_retries=5, initial_backoff=10):\n",
    "    \"\"\"\n",
    "    Rerank search results using Cohere's rerank model with rate limit handling.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's question\n",
    "        search_results: List of search results from vector search\n",
    "        top_k: Number of top results to return after reranking\n",
    "        max_retries: Maximum number of retry attempts for rate-limited requests\n",
    "        initial_backoff: Initial backoff time in seconds (will increase exponentially)\n",
    "    \n",
    "    Returns:\n",
    "        List of reranked results\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    # Extract texts from search results\n",
    "    documents = [result.get('text', '') for result in search_results]\n",
    "    \n",
    "    # Implement retry with exponential backoff for rate limit handling\n",
    "    retry_count = 0\n",
    "    backoff_time = initial_backoff\n",
    "    \n",
    "    while retry_count <= max_retries:\n",
    "        try:\n",
    "            # Call Cohere rerank\n",
    "            rerank_response = cohere_client.rerank(\n",
    "                query=query,\n",
    "                documents=documents,\n",
    "                model='rerank-english-v3.0',  # Latest rerank model\n",
    "                top_n=top_k\n",
    "            )\n",
    "            \n",
    "            # Return reranked results maintaining original structure\n",
    "            reranked_results = []\n",
    "            for result in rerank_response.results:\n",
    "                original_result = search_results[result.index].copy()\n",
    "                original_result['rerank_score'] = result.relevance_score\n",
    "                reranked_results.append(original_result)\n",
    "            \n",
    "            return reranked_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Check if it's a rate limit error (429)\n",
    "            if hasattr(e, 'status_code') and e.status_code == 429:\n",
    "                if retry_count < max_retries:\n",
    "                    print(f\"‚ö†Ô∏è Rate limit reached. Waiting for {backoff_time} seconds before retrying...\")\n",
    "                    time.sleep(backoff_time)\n",
    "                    # Exponential backoff\n",
    "                    backoff_time *= 2\n",
    "                    retry_count += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"‚ùå Maximum retries ({max_retries}) reached. Falling back to vector search results.\")\n",
    "            else:\n",
    "                print(f\"‚ùå Error during reranking: {str(e)}\")\n",
    "            \n",
    "            # Fallback: return the top_k results from the original search\n",
    "            print(\"‚ö†Ô∏è Using original vector search results without reranking.\")\n",
    "            return search_results[:top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Create Enhanced Answer Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_with_rerank(question, initial_top_k=10, final_top_k=1):\n",
    "    \"\"\"\n",
    "    Generate answer using reranked results.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        initial_top_k: Number of candidates to retrieve from vector search\n",
    "        final_top_k: Number of results to keep after reranking\n",
    "    \n",
    "    Returns:\n",
    "        Generated answer\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieval - get more candidates\n",
    "    search_results = vector_search(question, top_k=initial_top_k)\n",
    "    \n",
    "    # Step 2: Reranking - select best results\n",
    "    reranked_results = rerank_results(question, search_results, top_k=final_top_k)\n",
    "    \n",
    "    # Step 3: Generation - use reranked results\n",
    "    prompt = prompt_template(question, reranked_results)\n",
    "    return model_generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Compare Results: Naive RAG vs. Reranked RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARISON: Naive RAG vs. Reranked RAG\n",
      "================================================================================\n",
      "\n",
      "Question: What was the first working deep learning algorithm and who published it?\n",
      "\n",
      "=== Without Reranking (Top 3 by vector similarity) ===\n",
      "\n",
      "1. A 1971 paper described a deep network with eight layers trained by this method, which is based on layer by layer training through regression analysis. Superfluous hidden units are pruned using a separ...\n",
      "\n",
      "2. first perceptrons did not have adaptive hidden units. However, Joseph (1960) also discussed multilayer perceptrons with an adaptive hidden layer. Rosenblatt (1962): section 16 cited and adopted these ...\n",
      "\n",
      "3. the 1920s, Wilhelm Lenz and Ernst Ising created the Ising model which is essentially a non-learning RNN architecture consisting of neuron-like threshold elements. In 1972, Shun'ichi Amari made this ar...\n",
      "\n",
      "üìù Answer (Naive RAG):\n",
      "The first deep learning multilayer perceptron trained by stochastic gradient descent was published in 1967 by Shun'ichi Amari.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== With Cohere Reranking (Top 3 from 10 candidates) ===\n",
      "\n",
      "1. [Rerank Score: 1.000] (Title: Deep learning) the 1920s, Wilhelm Lenz and Ernst Ising created the Ising model which is essentially a non-learning RNN architecture consisting of neuron-like threshold elements. In 1972, Shun'ichi Amari made this ar...\n",
      "\n",
      "2. [Rerank Score: 1.000] (Title: Artificial neural network) first perceptrons did not have adaptive hidden units. However, Joseph (1960) also discussed multilayer perceptrons with an adaptive hidden layer. Rosenblatt (1962): section 16 cited and adopted these ...\n",
      "\n",
      "3. [Rerank Score: 0.995] (Title: Deep learning) A 1971 paper described a deep network with eight layers trained by this method, which is based on layer by layer training through regression analysis. Superfluous hidden units are pruned using a separ...\n",
      "\n",
      "üìù Answer (Reranked RAG):\n",
      "```markdown\n",
      "The first working deep learning algorithm was the Group method of data handling, published by Alexey Ivakhnenko and Lapa in 1965.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Let's compare results on a challenging question\n",
    "test_question = \"What was the first working deep learning algorithm and who published it?\"\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPARISON: Naive RAG vs. Reranked RAG\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nQuestion: {test_question}\\n\")\n",
    "\n",
    "print(\"=== Without Reranking (Top 3 by vector similarity) ===\")\n",
    "search_results = vector_search(test_question, top_k=3)\n",
    "for i, result in enumerate(search_results):\n",
    "    print(f\"\\n{i+1}. {result['text'][:200]}...\")\n",
    "\n",
    "answer_naive = generate_answer(test_question)\n",
    "print(f\"\\nüìù Answer (Naive RAG):\\n{answer_naive}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"=== With Cohere Reranking (Top 3 from 10 candidates) ===\")\n",
    "search_results_extended = vector_search(test_question, top_k=10)\n",
    "reranked_results = rerank_results(test_question, search_results_extended, top_k=3)\n",
    "for i, result in enumerate(reranked_results):\n",
    "    title = result.get('title', 'Unknown')\n",
    "    print(f\"\\n{i+1}. [Rerank Score: {result['rerank_score']:.3f}] (Title: {title}) {result['text'][:200]}...\")\n",
    "\n",
    "answer_reranked = generate_answer_with_rerank(test_question)\n",
    "print(f\"\\nüìù Answer (Reranked RAG):\\n{answer_reranked}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Evaluate Improvement with RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating RAG system with Cohere Reranking...\n",
      "This will evaluate the improved system on the same 15 questions...\n",
      "\n",
      "‚úÖ Loaded 14 questions from evaluation dataset\n",
      "\n",
      "Evaluating 14 questions...\n",
      "\n",
      "Question 1/14: Who introduced the ReLU (rectified linear unit) ac...\n",
      "Question 2/14: What was the first working deep learning algorithm...\n",
      "Question 3/14: Which CNN achieved superhuman performance in a vis...\n",
      "Question 4/14: When was BERT introduced and by which organization...\n",
      "Question 5/14: What are the two model sizes BERT was originally i...\n",
      "Question 6/14: What percentage of tokens are randomly selected fo...\n",
      "Question 7/14: Who introduced the term 'deep learning' to the mac...\n",
      "Question 8/14: Which three researchers were awarded the 2018 Turi...\n",
      "Question 9/14: When was the first GPT introduced and by which org...\n",
      "Question 10/14: What were the three parameter sizes of the first v...\n",
      "Question 11/14: What is the 'one in ten rule' in regression analys...\n",
      "Question 12/14: What is the essence of overfitting according to th...\n",
      "Question 13/14: In which year and paper was the modern version of ...\n",
      "Question 14/14: What value did the original Transformer paper use ...\n",
      "\n",
      "üîç Running RAGAS evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cecb005c15f4264bca061de7740b240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAGAS EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "üìã INDIVIDUAL QUESTION SCORES:\n",
      "------------------------------------------------------------\n",
      " 1. üü¢ 1.000 - Who introduced the ReLU (rectified linear unit) activation f...\n",
      " 2. üü¢ 1.000 - What was the first working deep learning algorithm and who p...\n",
      " 3. üü¢ 1.000 - Which CNN achieved superhuman performance in a visual patter...\n",
      " 4. üü¢ 1.000 - When was BERT introduced and by which organization?\n",
      " 5. üü¢ 1.000 - What are the two model sizes BERT was originally implemented...\n",
      " 6. üü¢ 1.000 - What percentage of tokens are randomly selected for the mask...\n",
      " 7. üü¢ 1.000 - Who introduced the term 'deep learning' to the machine learn...\n",
      " 8. üü¢ 1.000 - Which three researchers were awarded the 2018 Turing Award f...\n",
      " 9. üü¢ 1.000 - When was the first GPT introduced and by which organization?\n",
      "10. üü¢ 1.000 - What were the three parameter sizes of the first versions of...\n",
      "11. üü¢ 1.000 - What is the 'one in ten rule' in regression analysis?\n",
      "12. üü¢ 1.000 - What is the essence of overfitting according to the article?\n",
      "13. üü¢ 1.000 - In which year and paper was the modern version of the transf...\n",
      "14. üü¢ 1.000 - What value did the original Transformer paper use for the pa...\n",
      "\n",
      "============================================================\n",
      "üìä AGGREGATE RESULTS\n",
      "============================================================\n",
      "\n",
      "CONTEXT RECALL METRIC (0.0 - 1.0 scale):\n",
      "  üü¢ Context Recall: 1.000\n",
      "============================================================\n",
      "\n",
      "üí° Tip: Add show_detailed=True to see full question details\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation with reranking\n",
    "print(\"üîç Evaluating RAG system with Cohere Reranking...\")\n",
    "print(\"This will evaluate the improved system on the same 15 questions...\\n\")\n",
    "\n",
    "reranked_results = evaluate_naive_rag_v2(\n",
    "    vector_search_func=lambda q: vector_search(q, top_k=15),\n",
    "    generate_answer_func=generate_answer_with_rerank\n",
    ")\n",
    "\n",
    "# Store reranked scores\n",
    "reranked_scores = reranked_results.get('aggregate_scores', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä IMPROVEMENT WITH RERANKING\n",
      "============================================================\n",
      "\n",
      "Context Recall:\n",
      "  Baseline: 0.714\n",
      "  With Reranking: 1.000\n",
      "  Improvement: +0.286 (+40.0%)\n",
      "\n",
      "============================================================\n",
      "\n",
      "üéâ Key Insights:\n",
      "‚Ä¢ Reranking typically improves context precision significantly\n",
      "‚Ä¢ Better context selection leads to more accurate answers\n",
      "‚Ä¢ The cross-encoder architecture of rerankers captures nuanced relevance\n",
      "‚Ä¢ This is especially valuable for complex or ambiguous queries\n"
     ]
    }
   ],
   "source": [
    "# Compare improvements\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä IMPROVEMENT WITH RERANKING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for metric in ['context_recall']:\n",
    "    if metric in baseline_scores and metric in reranked_scores:\n",
    "        baseline = baseline_scores[metric]\n",
    "        reranked = reranked_scores[metric]\n",
    "        improvement = reranked - baseline\n",
    "        improvement_pct = (improvement / baseline) * 100 if baseline > 0 else 0\n",
    "        \n",
    "        print(f\"\\n{metric.replace('_', ' ').title()}:\")\n",
    "        print(f\"  Baseline: {baseline:.3f}\")\n",
    "        print(f\"  With Reranking: {reranked:.3f}\")\n",
    "        print(f\"  Improvement: {improvement:+.3f} ({improvement_pct:+.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nüéâ Key Insights:\")\n",
    "print(\"‚Ä¢ Reranking typically improves context precision significantly\")\n",
    "print(\"‚Ä¢ Better context selection leads to more accurate answers\")\n",
    "print(\"‚Ä¢ The cross-encoder architecture of rerankers captures nuanced relevance\")\n",
    "print(\"‚Ä¢ This is especially valuable for complex or ambiguous queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Next Steps\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **Naive RAG Limitations**: While vector search is effective, it can miss nuanced relevance\n",
    "2. **Reranking Benefits**: Cross-encoder models like Cohere's reranker significantly improve context selection\n",
    "3. **Measurable Improvements**: RAGAS metrics clearly show the performance gains\n",
    "\n",
    "### Architecture Comparison\n",
    "\n",
    "**Naive RAG:**\n",
    "```\n",
    "Query ‚Üí Embedding ‚Üí Vector Search (Top 3) ‚Üí Generate Answer\n",
    "```\n",
    "\n",
    "**Reranked RAG:**\n",
    "```\n",
    "Query ‚Üí Embedding ‚Üí Vector Search (Top 10) ‚Üí Rerank (Top 3) ‚Üí Generate Answer\n",
    "```\n",
    "\n",
    "### When to Use Reranking\n",
    "\n",
    "‚úÖ **Use reranking when:**\n",
    "- Answer quality is critical\n",
    "- You have complex, nuanced queries\n",
    "- Your corpus contains similar but subtly different content\n",
    "- You can afford the additional API call latency\n",
    "\n",
    "‚ùå **Skip reranking when:**\n",
    "- Speed is more important than accuracy\n",
    "- Queries are simple and unambiguous\n",
    "- Your corpus has clearly distinct topics\n",
    "\n",
    "### Further Improvements\n",
    "\n",
    "1. **Hybrid Search**: Combine vector search with keyword search\n",
    "2. **Query Expansion**: Generate multiple query variations\n",
    "3. **Document Expansion**: Add metadata and summaries to chunks\n",
    "4. **Fine-tuning**: Train custom rerankers on your domain\n",
    "5. **Caching**: Store reranked results for common queries\n",
    "\n",
    "### Try It Yourself!\n",
    "\n",
    "Experiment with:\n",
    "- Different `initial_top_k` values (try 20, 50)\n",
    "- Different `final_top_k` values (try 5, 7)\n",
    "- Different reranking models\n",
    "- Your own questions and see the improvement!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
