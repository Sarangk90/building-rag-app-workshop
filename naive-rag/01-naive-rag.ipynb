{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Workshop Notebook - Naive RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:41:00.806624Z",
     "start_time": "2025-07-28T09:41:00.799782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion:\n",
    "1. Load pre-downloaded Wikipedia articles from the data directory.\n",
    "2. Chunk the text into smaller pieces to create embeddings.\n",
    "3. Create embeddings using OpenAI's text-embedding-3-small model.\n",
    "4. Index the embeddings using Qdrant Vector Store.\n",
    "\n",
    "![../imgs/ingestion.png](../imgs/ingestion.png)\n",
    "\n",
    "**Note**: Articles are pre-downloaded to avoid repetitive API calls during workshops. Use `scripts/fetch_additional_articles.py` to fetch new articles when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load pre-downloaded Wikipedia articles\n",
    "\n",
    "**Configuration Options**: Easily change which articles to load by modifying the variables in the next cell:\n",
    "- **Specific articles**: Set `SELECTED_ARTICLES` list\n",
    "- **Predefined combinations**: Uncomment and use `SELECTED_COMBINATION` \n",
    "- **All articles**: Use `load_existing_wiki_articles()` without parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:41:01.644347Z",
     "start_time": "2025-07-28T09:41:00.899991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 2 articles\n",
      "1. Artificial neural network\n",
      "2. Deep learning\n"
     ]
    }
   ],
   "source": [
    "# Import the wiki article loader utility\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from wiki_article_loader import load_existing_wiki_articles\n",
    "\n",
    "# === CONFIGURABLE: Choose which articles to load ===\n",
    "# Uncomment one of the options below:\n",
    "\n",
    "# Option 1: Load specific articles (recommended for focused learning)\n",
    "articles = load_existing_wiki_articles(\"../data/wiki_articles\", [\"Deep learning\", \"Artificial neural network\"])\n",
    "\n",
    "# Option 2: Load all available articles\n",
    "# articles = load_existing_wiki_articles(\"../data/wiki_articles\")\n",
    "\n",
    "print(f\"Successfully loaded {len(articles)} articles\")\n",
    "for i, article in enumerate(articles, 1):\n",
    "    print(f\"{i}. {article['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Verify loaded articles (text is already cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:41:16.879780Z",
     "start_time": "2025-07-28T09:41:01.660867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded articles summary:\n",
      "- Artificial neural network: 57,787 characters\n",
      "- Deep learning: 56,760 characters\n",
      "\n",
      "Total articles: 2\n",
      "Total content: 114,547 characters\n"
     ]
    }
   ],
   "source": [
    "# Articles are already cleaned and ready to use\n",
    "# The pre-downloaded articles have markup and citations removed\n",
    "\n",
    "print(f\"Loaded articles summary:\")\n",
    "for article in articles:\n",
    "    content_length = len(article['content'])\n",
    "    print(f\"- {article['title']}: {content_length:,} characters\")\n",
    "\n",
    "print(f\"\\nTotal articles: {len(articles)}\")\n",
    "print(f\"Total content: {sum(len(a['content']) for a in articles):,} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:41:16.893362Z",
     "start_time": "2025-07-28T09:41:16.889743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.\\nSome common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board ga'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[1]['content'][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Chunk the text into smaller pieces to create embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:41:16.908850Z",
     "start_time": "2025-07-28T09:41:16.904399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Chunking function\n",
    "def chunk_text(text, chunk_size=300, overlap=50):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i + chunk_size])\n",
    "            for i in range(0, len(words), chunk_size - overlap)]\n",
    "\n",
    "\n",
    "# Prepare chunks and metadata\n",
    "corpus = []\n",
    "metadata = []\n",
    "for article in articles:\n",
    "    chunks = chunk_text(article[\"content\"])\n",
    "    corpus.extend(chunks)\n",
    "    metadata.extend([{\"title\": article[\"title\"], \"url\": article[\"url\"]}] * len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:41:16.920193Z",
     "start_time": "2025-07-28T09:41:16.918175Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Corpus: 67\n",
      "Total Metadata: 67\n"
     ]
    }
   ],
   "source": [
    "print('Total Corpus:', len(corpus))\n",
    "print('Total Metadata:', len(metadata))\n",
    "\n",
    "deep_learning_chunks = [chunk for chunk, meta in zip(corpus, metadata) if meta['title'] == 'Deep learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:41:16.936650Z",
     "start_time": "2025-07-28T09:41:16.934693Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deep_learning_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Create embeddings using OpenAI's text-embedding-3-small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:41:17.259669Z",
     "start_time": "2025-07-28T09:41:16.957764Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "\n",
    "# Define the embedding function using OpenAI's API (using text-embedding-ada-002)\n",
    "def openai_embedding(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=[text],  # Passing the text as a list\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    # Use dot notation to access the embedding from the response object\n",
    "    embeddings = [data.embedding for data in response.data]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:44:04.656758Z",
     "start_time": "2025-07-28T09:41:17.265346Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:18<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "embeddings = []\n",
    "chunked_texts = []\n",
    "metadata_chunks = []\n",
    "# test_corpus = corpus[:10]\n",
    "\n",
    "for chunk in tqdm(corpus):\n",
    "    embedding = openai_embedding(chunk)\n",
    "    embeddings.extend(embedding)\n",
    "    chunked_texts.extend([chunk] * len(embedding))\n",
    "    time.sleep(0.4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1.5. Index the embeddings using Qdrant Vector Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:44:05.129333Z",
     "start_time": "2025-07-28T09:44:04.672080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "\n",
    "# Create an in-memory Qdrant instance\n",
    "client = QdrantClient(\":memory:\")\n",
    "collection_name = \"wikipedia_articles\"\n",
    "\n",
    "# Create the collection with the specified vector configuration\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Upsert points into the collection using PointStruct for each point\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=[\n",
    "        PointStruct(\n",
    "            id=idx,\n",
    "            vector=embedding,\n",
    "            payload={\"text\": chunked_texts[idx]}\n",
    "        )\n",
    "        for idx, embedding in enumerate(embeddings)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. Build the Q/A Chatbot\n",
    "\n",
    "![../imgs/naive-rag.png](../imgs/naive-rag.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Retrieval - Search the database for the most relevant embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:44:05.880599Z",
     "start_time": "2025-07-28T09:44:05.137215Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'In machine learning, deep learning focuses on utilizing '\n",
      "          'multilayered neural networks to perform tasks such as '\n",
      "          'classification, regression, and representation learning. The field '\n",
      "          'takes inspiration from biological neuroscience and is centered '\n",
      "          'around stacking artificial neurons into layers and \"training\" them '\n",
      "          'to process data. The adjective \"deep\" refers to the use of multiple '\n",
      "          'layers (ranging from three to several hundred or thousands) in the '\n",
      "          'network. Methods used can be supervised, semi-supervised or '\n",
      "          'unsupervised. Some common deep learning network architectures '\n",
      "          'include fully connected networks, deep belief networks, recurrent '\n",
      "          'neural networks, convolutional neural networks, generative '\n",
      "          'adversarial networks, transformers, and neural radiance fields. '\n",
      "          'These architectures have been applied to fields including computer '\n",
      "          'vision, speech recognition, natural language processing, machine '\n",
      "          'translation, bioinformatics, drug design, medical image analysis, '\n",
      "          'climate science, material inspection and board game programs, where '\n",
      "          'they have produced results comparable to and in some cases '\n",
      "          'surpassing human expert performance. Early forms of neural networks '\n",
      "          'were inspired by information processing and distributed '\n",
      "          'communication nodes in biological systems, particularly the human '\n",
      "          'brain. However, current neural networks do not intend to model the '\n",
      "          'brain function of organisms, and are generally seen as low-quality '\n",
      "          'models for that purpose. Overview Most modern deep learning models '\n",
      "          'are based on multi-layered neural networks such as convolutional '\n",
      "          'neural networks and transformers, although they can also include '\n",
      "          'propositional formulas or latent variables organized layer-wise in '\n",
      "          'deep generative models such as the nodes in deep belief networks '\n",
      "          'and deep Boltzmann machines. Fundamentally, deep learning refers to '\n",
      "          'a class of machine learning algorithms in which a hierarchy of '\n",
      "          'layers is used to transform input data into a progressively more '\n",
      "          'abstract and composite representation. For example, in an image '\n",
      "          'recognition model, the raw input may be an image (represented as a '\n",
      "          'tensor of pixels). The first representational layer may attempt to '\n",
      "          'identify basic shapes such as'},\n",
      " {'text': 'a hierarchy of layers is used to transform input data into a '\n",
      "          'progressively more abstract and composite representation. For '\n",
      "          'example, in an image recognition model, the raw input may be an '\n",
      "          'image (represented as a tensor of pixels). The first '\n",
      "          'representational layer may attempt to identify basic shapes such as '\n",
      "          'lines and circles, the second layer may compose and encode '\n",
      "          'arrangements of edges, the third layer may encode a nose and eyes, '\n",
      "          'and the fourth layer may recognize that the image contains a face. '\n",
      "          'Importantly, a deep learning process can learn which features to '\n",
      "          'optimally place at which level on its own. Prior to deep learning, '\n",
      "          'machine learning techniques often involved hand-crafted feature '\n",
      "          'engineering to transform the data into a more suitable '\n",
      "          'representation for a classification algorithm to operate on. In the '\n",
      "          'deep learning approach, features are not hand-crafted and the model '\n",
      "          'discovers useful feature representations from the data '\n",
      "          'automatically. This does not eliminate the need for hand-tuning; '\n",
      "          'for example, varying numbers of layers and layer sizes can provide '\n",
      "          'different degrees of abstraction. The word \"deep\" in \"deep '\n",
      "          'learning\" refers to the number of layers through which the data is '\n",
      "          'transformed. More precisely, deep learning systems have a '\n",
      "          'substantial credit assignment path (CAP) depth. The CAP is the '\n",
      "          'chain of transformations from input to output. CAPs describe '\n",
      "          'potentially causal connections between input and output. For a '\n",
      "          'feedforward neural network, the depth of the CAPs is that of the '\n",
      "          'network and is the number of hidden layers plus one (as the output '\n",
      "          'layer is also parameterized). For recurrent neural networks, in '\n",
      "          'which a signal may propagate through a layer more than once, the '\n",
      "          'CAP depth is potentially unlimited. No universally agreed-upon '\n",
      "          'threshold of depth divides shallow learning from deep learning, but '\n",
      "          'most researchers agree that deep learning involves CAP depth '\n",
      "          'higher'},\n",
      " {'text': 'learning to provide a robot with the ability to learn new tasks '\n",
      "          'through observation. Using Deep TAMER, a robot learned a task with '\n",
      "          'a human trainer, watching video streams or observing a human '\n",
      "          'perform a task in-person. The robot later practiced the task with '\n",
      "          'the help of some coaching from the trainer, who provided feedback '\n",
      "          'such as \"good job\" and \"bad job\". Criticism and comment Deep '\n",
      "          'learning has attracted both criticism and comment, in some cases '\n",
      "          'from outside the field of computer science. Theory A main criticism '\n",
      "          'concerns the lack of theory surrounding some methods. Learning in '\n",
      "          'the most common deep architectures is implemented using '\n",
      "          'well-understood gradient descent. However, the theory surrounding '\n",
      "          'other algorithms, such as contrastive divergence is less clear. '\n",
      "          '(e.g., Does it converge? If so, how fast? What is it '\n",
      "          'approximating?) Deep learning methods are often looked at as a '\n",
      "          'black box, with most confirmations done empirically, rather than '\n",
      "          'theoretically. In further reference to the idea that artistic '\n",
      "          'sensitivity might be inherent in relatively low levels of the '\n",
      "          'cognitive hierarchy, a published series of graphic representations '\n",
      "          'of the internal states of deep (20-30 layers) neural networks '\n",
      "          'attempting to discern within essentially random data the images on '\n",
      "          'which they were trained demonstrate a visual appeal: the original '\n",
      "          'research notice received well over 1,000 comments, and was the '\n",
      "          'subject of what was for a time the most frequently accessed article '\n",
      "          \"on The Guardian's website. Furthermore, some researchers have \"\n",
      "          'argued that standard loss functions and differentiable '\n",
      "          'architectures in deep learning may limit the discovery of deeper '\n",
      "          'causal or generative mechanisms. Building on Algorithmic '\n",
      "          'information theory (AIT), Hernández-Orozco et al. (2021) proposed '\n",
      "          'an algorithmic loss function to measure the discrepancy between '\n",
      "          'predicted and observed system behavior. Their approach integrates '\n",
      "          'AIT with Machine learning to formulate a framework for learning '\n",
      "          'generative rules in'}]\n"
     ]
    }
   ],
   "source": [
    "# Function to search the database\n",
    "def vector_search(query, top_k=3):\n",
    "    # create embedding of the query\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    query_embeddings = response.data[0].embedding\n",
    "    # similarity search using the embedding, give top n results which are close to the query embeddings\n",
    "    search_result = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_embeddings,\n",
    "        with_payload=True,\n",
    "        limit=top_k,\n",
    "    ).points\n",
    "    return [result.payload for result in search_result]\n",
    "\n",
    "\n",
    "search_result = vector_search(\"What does the word 'deep' in 'deep learning' refer\")\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Generation - Use the retrieved embeddings to generate the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:44:05.895247Z",
     "start_time": "2025-07-28T09:44:05.892679Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_generate(prompt, model=\"gpt-4o\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:44:05.908398Z",
     "start_time": "2025-07-28T09:44:05.906346Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def prompt_template(question, context):\n",
    "    return \"\"\"You are a AI Assistant that provides answer to the question at the end, over the following\n",
    "  pieces of context. Make sure to only use the context to answer the question. Keep the wording very close to the context\n",
    "  context:\n",
    "  ```\n",
    "  \"\"\" + json.dumps(context) + \"\"\"\n",
    "  ```\n",
    "  User question: \"\"\" + question + \"\"\"\n",
    "  Answer in markdown:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:44:07.868665Z",
     "start_time": "2025-07-28T09:44:05.916641Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output, describing potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. Most researchers agree that deep learning involves CAP depth higher than two.\n"
     ]
    }
   ],
   "source": [
    "def generate_answer(question):\n",
    "    #Retrieval: search a knowledge base.\n",
    "    search_result = vector_search(question)\n",
    "\n",
    "    prompt = prompt_template(question, search_result)\n",
    "    # Generation: LLMs' ability to generate the answer\n",
    "    return model_generate(prompt)\n",
    "\n",
    "\n",
    "question = f\"What does the word 'deep' in 'deep learning' refer? \"\n",
    "answer = generate_answer(question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:44:09.314306Z",
     "start_time": "2025-07-28T09:44:07.883340Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ```markdown\n",
      "The time delay neural network (TDNN) was introduced by Alex Waibel in 1987.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "question = f\"Who introduced the time delay neural network (TDNN)? and when ?\"\n",
    "answer = generate_answer(question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T09:44:09.332800Z",
     "start_time": "2025-07-28T09:44:09.331205Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
