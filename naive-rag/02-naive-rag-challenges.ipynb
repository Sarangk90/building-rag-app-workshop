{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Workshop - Naive RAG Challenges\n",
    "\n",
    "This notebook demonstrates the key limitations of naive RAG systems using our extended Wikipedia dataset. We'll focus on scenarios that clearly show where naive RAG fails and why advanced techniques are necessary.\n",
    "\n",
    "## Dataset Overview:\n",
    "\n",
    "- **61 articles** including Wikipedia + long technical blogs from Lilian Weng, arXiv papers\n",
    "- **1,210 pre-chunked** pieces with 300 character chunks, 50 character overlap\n",
    "- **Pre-embedded** using OpenAI text-embedding-3-small\n",
    "- **Cloud-hosted** on Qdrant for reliable access\n",
    "- **Includes cross-domain articles** to demonstrate naive RAG limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Pre-Populated Qdrant Cloud Collection\n",
    "\n",
    "Instead of fetching and processing data, we'll connect directly to a pre-populated Qdrant Cloud collection containing the extended Wikipedia dataset.\n",
    "\n",
    "**Note**: The ingestion process has already been completed using our automated scripts!\n",
    "\n",
    "### Please use the API Key provided by instructor to access the preuploaded collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Qdrant Cloud\n",
      "üìö Collection: workshop_wikipedia_extended\n",
      "ü§ñ Embedding model: text-embedding-3-small\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# Initialize Qdrant Cloud client\n",
    "qdrant_client = QdrantClient(\n",
    "    url=os.getenv(\"QDRANT_URL\"),\n",
    "    api_key=os.getenv(\"QDRANT_API_KEY\")\n",
    ")\n",
    "\n",
    "# Collection configuration\n",
    "collection_name = \"workshop_wikipedia_extended\"\n",
    "embedding_model = \"text-embedding-3-small\"\n",
    "\n",
    "print(f\"‚úÖ Connected to Qdrant Cloud\")\n",
    "print(f\"üìö Collection: {collection_name}\")\n",
    "print(f\"ü§ñ Embedding model: {embedding_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Verify Collection and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Collection Statistics:\n",
      "   Total chunks: 1,210\n",
      "   Vector dimension: 1536\n",
      "   Distance metric: Cosine\n",
      "\n",
      "üìù Sample data structure:\n",
      "\n",
      "Chunk 1:\n",
      "   Title: BERT (language model)\n",
      "   Text preview: Bidirectional encoder representations from transformers (BERT) is a language model introduced in Oct...\n",
      "   Chunk 1 of 10\n",
      "\n",
      "Chunk 2:\n",
      "   Title: BERT (language model)\n",
      "   Text preview: Euclidean space. Encoder: a stack of Transformer blocks with self-attention, but without causal mask...\n",
      "   Chunk 2 of 10\n",
      "\n",
      "Chunk 3:\n",
      "   Title: BERT (language model)\n",
      "   Text preview: consists of a sinusoidal function that takes the position in the sequence as input. Segment type: Us...\n",
      "   Chunk 3 of 10\n"
     ]
    }
   ],
   "source": [
    "# Get collection information\n",
    "collection_info = qdrant_client.get_collection(collection_name)\n",
    "point_count = collection_info.points_count\n",
    "\n",
    "print(f\"üìä Collection Statistics:\")\n",
    "print(f\"   Total chunks: {point_count:,}\")\n",
    "print(f\"   Vector dimension: {collection_info.config.params.vectors.size}\")\n",
    "print(f\"   Distance metric: {collection_info.config.params.vectors.distance}\")\n",
    "\n",
    "# Sample a few points to see the data structure\n",
    "sample_points = qdrant_client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    limit=3,\n",
    "    with_payload=True,\n",
    "    with_vectors=False\n",
    ")[0]\n",
    "\n",
    "print(f\"\\nüìù Sample data structure:\")\n",
    "for i, point in enumerate(sample_points):\n",
    "    payload = point.payload\n",
    "    print(f\"\\nChunk {i+1}:\")\n",
    "    print(f\"   Title: {payload.get('title', 'Unknown')}\")\n",
    "    print(f\"   Text preview: {payload.get('text', '')[:100]}...\")\n",
    "    print(f\"   Chunk {payload.get('chunk_index', 0)+1} of {payload.get('total_chunks', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Q/A Chatbot\n",
    "\n",
    "Now we can focus on the core RAG functionality without worrying about data preparation!\n",
    "\n",
    "![../imgs/naive-rag.png](../imgs/naive-rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Retrieval - Search the cloud database for relevant embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query, top_k=2):\n",
    "    \"\"\"Search the Qdrant Cloud collection for relevant chunks.\"\"\"\n",
    "    # Create embedding of the query\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=query,\n",
    "        model=embedding_model\n",
    "    )\n",
    "    query_embeddings = response.data[0].embedding\n",
    "    \n",
    "    # Similarity search using the embedding\n",
    "    search_result = qdrant_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_embeddings,\n",
    "        with_payload=True,\n",
    "        limit=top_k,\n",
    "    ).points\n",
    "    \n",
    "    return [result.payload for result in search_result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Generation - Use retrieved chunks to generate answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def model_generate(prompt, model=\"gpt-4o\"):\n",
    "    \"\"\"Generate response using OpenAI's chat completion.\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # Deterministic output\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def prompt_template(question, context):\n",
    "    \"\"\"Create a prompt template for RAG.\"\"\"\n",
    "    return f\"\"\"You are an AI Assistant that provides answers to questions based on the following context. \n",
    "Make sure to only use the context to answer the question. Keep the wording very close to the context.\n",
    "\n",
    "Context:\n",
    "```\n",
    "{json.dumps(context)}\n",
    "```\n",
    "\n",
    "User question: {question}\n",
    "\n",
    "Answer in markdown:\"\"\"\n",
    "\n",
    "def generate_answer(question):\n",
    "    \"\"\"Complete RAG pipeline: retrieve and generate.\"\"\"\n",
    "    # Retrieval: search the knowledge base\n",
    "    search_result = vector_search(question)\n",
    "    if not search_result:\n",
    "        return \"No relevant information found.\"\n",
    "        \n",
    "    \n",
    "    # Generation: create prompt and generate answer\n",
    "    prompt = prompt_template(question, search_result)\n",
    "    return model_generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Test Basic RAG Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Question: What is the tokenizer of BERT, which is a sub-word strategy like byte-pair encoding?\n",
      "\n",
      "üìö Retrieved Sources:\n",
      "\n",
      "ü§ñ Generated Answer:\n",
      "```markdown\n",
      "The tokenizer of BERT is WordPiece, which is a sub-word strategy like byte-pair encoding.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Test with a clear, unambiguous question first\n",
    "question = \"What does the word 'deep' in 'deep learning' refer to?\"\n",
    "search_result = vector_search(question, top_k=3)\n",
    "\n",
    "print(f\"üîç Question: {question}\")\n",
    "print(f\"\\nüìö Retrieved Sources:\")\n",
    "\n",
    "# Generate answer\n",
    "answer = generate_answer(question)\n",
    "print(f\"\\nü§ñ Generated Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Demonstrating Naive RAG Limitations\n",
    "\n",
    "Now let's test scenarios where naive RAG fails due to **terminology overlap** and **cross-domain confusion**. We'll focus only on cases that clearly demonstrate confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Confusion Test 1: Optimization Context Confusion\n",
    "\n",
    "This question should demonstrate confusion between mathematical optimization and machine learning optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ CONFUSION TEST 1: What is optimization in machine learning?\n",
      "============================================================\n",
      "üìö Retrieved Sources:\n",
      "\n",
      "1. Mathematical optimization\n",
      "   Preview: Mathematical optimization (alternatively spelled optimisation) or mathematical programming is the selection of a best el...\n",
      "\n",
      "2. Optimization (mathematics)\n",
      "   Preview: Mathematical optimization (alternatively spelled optimisation) or mathematical programming is the selection of a best el...\n",
      "\n",
      "3. Artificial neural network\n",
      "   Preview: If after learning, the error rate is too high, the network typically must be redesigned. Practically this is done by def...\n",
      "\n",
      "4. Mathematical optimization\n",
      "   Preview: recent and growing subset of this field is multidisciplinary design optimization, which, while useful in many problems, ...\n",
      "\n",
      "5. Optimization (mathematics)\n",
      "   Preview: recent and growing subset of this field is multidisciplinary design optimization, which, while useful in many problems, ...\n",
      "\n",
      "üîç Analysis:\n",
      "   Optimization contexts found: Mathematical Optimization, ML Optimization\n",
      "   ‚ö†Ô∏è  CONFUSION DETECTED: Multiple optimization contexts mixed\n",
      "\n",
      "ü§ñ Generated Answer:\n",
      "```markdown\n",
      "Mathematical optimization, or mathematical programming, is the selection of a best element, with regard to some criteria, from some set of available alternatives. It is generally divided into two subfields: discrete optimization and continuous optimization. Optimization problems arise in all quantitative disciplines from computer science and engineering to operations research and economics, and the development of solution methods has been of interest in mathematics for centuries. In the more general approach, an optimization problem consists of maximizing or minimizing a real function by systematically choosing input values from within an allowed set and computing the value of the function. The generalization of optimization theory and techniques to other formulations constitutes a large area of applied mathematics.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "confusion_question_1 = \"What is optimization in machine learning?\"\n",
    "\n",
    "print(f\"üß™ CONFUSION TEST 1: {confusion_question_1}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get detailed search results\n",
    "results = vector_search(confusion_question_1, top_k=5)\n",
    "\n",
    "print(f\"üìö Retrieved Sources:\")\n",
    "optimization_contexts = set()\n",
    "for i, result in enumerate(results):\n",
    "    title = result.get('title', 'Unknown')\n",
    "    text = result.get('text', '')\n",
    "    text_preview = text[:120]\n",
    "    print(f\"\\n{i+1}. {title}\")\n",
    "    print(f\"   Preview: {text_preview}...\")\n",
    "    \n",
    "    # Categorize optimization contexts\n",
    "    if any(term in title.lower() for term in ['mathematical optimization', 'optimization (mathematics)']):\n",
    "        optimization_contexts.add('Mathematical Optimization')\n",
    "    elif any(term in text.lower() for term in ['machine learning', 'neural network', 'gradient']):\n",
    "        optimization_contexts.add('ML Optimization')\n",
    "    elif any(term in text.lower() for term in ['evolutionary', 'genetic algorithm']):\n",
    "        optimization_contexts.add('Evolutionary Optimization')\n",
    "    elif 'optimization' in title.lower():\n",
    "        optimization_contexts.add('General Optimization')\n",
    "\n",
    "print(f\"\\nüîç Analysis:\")\n",
    "print(f\"   Optimization contexts found: {', '.join(optimization_contexts) if optimization_contexts else 'Mixed/Unclear'}\")\n",
    "\n",
    "if len(optimization_contexts) > 1:\n",
    "    print(f\"   ‚ö†Ô∏è  CONFUSION DETECTED: Multiple optimization contexts mixed\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Results focused on single optimization context\")\n",
    "\n",
    "# Generate answer\n",
    "answer = generate_answer(confusion_question_1)\n",
    "print(f\"\\nü§ñ Generated Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAG Evaluation with RAGAS\n",
    "\n",
    "Now let's evaluate our naive RAG system using **RAGAS** to establish baseline performance metrics and quantify the confusion we've observed.\n",
    "\n",
    "### Context-Focused Metrics:\n",
    "\n",
    "1. **Context Precision**: How well are relevant chunks ranked at the top?\n",
    "2. **Context Recall**: How much of the necessary information was retrieved?\n",
    "3. **Context Relevancy**: How relevant is the retrieved context to the question?\n",
    "\n",
    "We're using **RAGAS** because it's purpose-built for RAG evaluation and provides deep insights into context quality - the most critical component of RAG performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating your Naive RAG system with RAGAS...\n",
      "This will evaluate context quality metrics on 15 questions...\n",
      "\n",
      "‚úÖ Loaded 14 questions from evaluation dataset\n",
      "\n",
      "Evaluating 14 questions...\n",
      "\n",
      "Question 1/14: Who introduced the ReLU (rectified linear unit) ac...\n",
      "Question 2/14: What was the first working deep learning algorithm...\n",
      "Question 3/14: Which CNN achieved superhuman performance in a vis...\n",
      "Question 4/14: When was BERT introduced and by which organization...\n",
      "Question 5/14: What are the two model sizes BERT was originally i...\n",
      "Question 6/14: What percentage of tokens are randomly selected fo...\n",
      "Question 7/14: Who introduced the term 'deep learning' to the mac...\n",
      "Question 8/14: Which three researchers were awarded the 2018 Turi...\n",
      "Question 9/14: When was the first GPT introduced and by which org...\n",
      "Question 10/14: What were the three parameter sizes of the first v...\n",
      "Question 11/14: What is the 'one in ten rule' in regression analys...\n",
      "Question 12/14: What is the essence of overfitting according to th...\n",
      "Question 13/14: In which year and paper was the modern version of ...\n",
      "Question 14/14: What value did the original Transformer paper use ...\n",
      "\n",
      "üîç Running RAGAS evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5619210c45f47f29f1646af699af88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAGAS EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "CONTEXT RECALL METRIC (0.0 - 1.0 scale):\n",
      "  üü° Context Recall: 0.786\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Import the RAGAS evaluation utility\n",
    "from rag_evaluator_v2 import evaluate_naive_rag_v2\n",
    "\n",
    "# Run evaluation on the current RAG system using RAGAS\n",
    "print(\"üîç Evaluating your Naive RAG system with RAGAS...\")\n",
    "print(\"This will evaluate context quality metrics on 15 questions...\\n\")\n",
    "\n",
    "baseline_results = evaluate_naive_rag_v2(\n",
    "    vector_search_func=vector_search,\n",
    "    generate_answer_func=generate_answer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Confusion Analysis Summary\n",
    "\n",
    "Let's analyze the patterns of confusion we've observed and quantify the impact on RAG performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä NAIVE RAG CONFUSION ANALYSIS\n",
      "==================================================\n",
      "\n",
      "‚ùì Question: What are agents in AI systems?\n",
      "   Expected: Should focus on AI/ML agents\n",
      "   Retrieved from: Artificial intelligence, History of artificial intelligence, Artificial intelligence\n",
      "   Domains found: Wikipedia Articles\n",
      "   ‚úÖ Focused results\n",
      "\n",
      "‚ùì Question: What is the architecture of transformer models?\n",
      "   Expected: Should focus on transformer architecture\n",
      "   Retrieved from: Transformer (machine learning model), Transformer (machine learning model), Artificial neural network\n",
      "   Domains found: Wikipedia Articles, Transformer Articles\n",
      "   ‚ö†Ô∏è  CONFUSION: Mixed domains detected\n",
      "\n",
      "‚ùì Question: What is active learning in machine learning?\n",
      "   Expected: Should focus on active learning\n",
      "   Retrieved from: Artificial intelligence, Deep learning, Ensemble learning\n",
      "   Domains found: Wikipedia Articles\n",
      "   ‚úÖ Focused results\n",
      "\n",
      "‚ùì Question: What is optimization in machine learning?\n",
      "   Expected: Should focus on ML optimization\n",
      "   Retrieved from: Optimization (mathematics), Mathematical optimization, Artificial neural network\n",
      "   Domains found: Optimization Articles, Wikipedia Articles\n",
      "   ‚ö†Ô∏è  CONFUSION: Mixed domains detected\n",
      "\n",
      "üìà CONFUSION SUMMARY:\n",
      "   Confused queries: 2/4 (50.0%)\n",
      "\n",
      "üéØ SIGNIFICANT CONFUSION DETECTED!\n",
      "   The extended dataset successfully demonstrates naive RAG limitations.\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä NAIVE RAG CONFUSION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test our key confusion scenarios\n",
    "confusion_tests = [\n",
    "    (\"What are agents in AI systems?\", \"Should focus on AI/ML agents\"),\n",
    "    (\"What is the architecture of transformer models?\", \"Should focus on transformer architecture\"),\n",
    "    (\"What is active learning in machine learning?\", \"Should focus on active learning\"),\n",
    "    (\"What is optimization in machine learning?\", \"Should focus on ML optimization\")\n",
    "]\n",
    "\n",
    "confusion_detected = 0\n",
    "total_tests = len(confusion_tests)\n",
    "\n",
    "for question, expected_focus in confusion_tests:\n",
    "    results = vector_search(question, top_k=3)\n",
    "    titles = [r.get('title', '') for r in results]\n",
    "    \n",
    "    # Analyze domain mixing - check for articles from different sources\n",
    "    domains_found = set()\n",
    "    for title in titles:\n",
    "        title_lower = title.lower()\n",
    "        # Check for long articles\n",
    "        if 'lilianweng' in title_lower:\n",
    "            domains_found.add('Lilian Weng Blog')\n",
    "        elif 'arxiv' in title_lower:\n",
    "            domains_found.add('arXiv Papers')\n",
    "        elif any(term in title_lower for term in ['gpt', 'llama', 'bert']):\n",
    "            domains_found.add('Model-Specific Articles')\n",
    "        elif any(term in title_lower for term in ['transformer', 'attention']):\n",
    "            domains_found.add('Transformer Articles')\n",
    "        elif any(term in title_lower for term in ['optimization', 'mathematical']):\n",
    "            domains_found.add('Optimization Articles')\n",
    "        else:\n",
    "            domains_found.add('Wikipedia Articles')\n",
    "    \n",
    "    print(f\"\\n‚ùì Question: {question}\")\n",
    "    print(f\"   Expected: {expected_focus}\")\n",
    "    print(f\"   Retrieved from: {', '.join(titles)}\")\n",
    "    print(f\"   Domains found: {', '.join(domains_found)}\")\n",
    "    \n",
    "    if len(domains_found) > 1:\n",
    "        confusion_detected += 1\n",
    "        print(f\"   ‚ö†Ô∏è  CONFUSION: Mixed domains detected\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Focused results\")\n",
    "\n",
    "print(f\"\\nüìà CONFUSION SUMMARY:\")\n",
    "print(f\"   Confused queries: {confusion_detected}/{total_tests} ({confusion_detected/total_tests*100:.1f}%)\")\n",
    "\n",
    "if confusion_detected >= total_tests * 0.5:\n",
    "    print(f\"\\nüéØ SIGNIFICANT CONFUSION DETECTED!\")\n",
    "    print(f\"   The extended dataset successfully demonstrates naive RAG limitations.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Limited confusion observed.\")\n",
    "    print(f\"   Results suggest the current dataset may need refinement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary: Why We Need Advanced RAG Techniques\n",
    "\n",
    "Through our focused evaluation with the extended dataset, we've identified key limitations of naive RAG:\n",
    "\n",
    "### üìã Key Findings:\n",
    "\n",
    "1. **Terminology Overlap**: Simple vector similarity struggles with terms that have different meanings across domains (\"agent\", \"model\", \"learning\", \"optimization\")\n",
    "\n",
    "2. **Context Disambiguation**: The system cannot distinguish between semantically similar but contextually different concepts\n",
    "\n",
    "3. **Domain Boundary Issues**: Cross-domain vocabulary creates confusion when the same terms appear in different technical contexts\n",
    "\n",
    "4. **Ranking Limitations**: Most relevant information isn't always ranked first due to semantic similarity bias\n",
    "\n",
    "5. **Scale Challenges**: Performance degrades with larger, more diverse knowledge bases containing overlapping terminology\n",
    "\n",
    "### üéØ Next Steps:\n",
    "\n",
    "These limitations motivate the need for **Advanced RAG techniques**:\n",
    "\n",
    "- **Reranking**: Improve relevance of retrieved chunks using cross-encoders that understand context better\n",
    "- **Hybrid Search**: Combine semantic and keyword search for better coverage and precision\n",
    "- **Query Enhancement**: Improve query understanding and expansion to disambiguate intent\n",
    "- **Context Optimization**: Better chunk strategies and context assembly techniques\n",
    "- **Multi-step Reasoning**: Chain multiple retrieval steps for complex questions\n",
    "\n",
    "### üí° Benefits of This Focused Approach:\n",
    "\n",
    "- ‚úÖ **Clear Demonstrations**: Focused on scenarios that actually show confusion\n",
    "- ‚úÖ **Quantifiable Issues**: RAGAS metrics provide concrete evidence of limitations\n",
    "- ‚úÖ **Educational Value**: Students see exactly where and why naive RAG fails\n",
    "- ‚úÖ **Motivation for Advanced Techniques**: Clear justification for the complexity of advanced RAG\n",
    "- ‚úÖ **Realistic Scenarios**: Demonstrates actual challenges with larger knowledge bases\n",
    "\n",
    "**Ready for the next notebook**: Advanced RAG techniques that address these specific limitations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
