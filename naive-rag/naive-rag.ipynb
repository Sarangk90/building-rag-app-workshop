{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Workshop Notebook\n",
    "## From Naive RAG to Advanced Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:55:28.880454Z",
     "start_time": "2025-02-02T13:55:26.697400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in ./venv/lib/python3.11/site-packages (1.4.0)\r\n",
      "Requirement already satisfied: mwparserfromhell in ./venv/lib/python3.11/site-packages (0.6.6)\r\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.11/site-packages (4.12.3)\r\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.11/site-packages (1.61.0)\r\n",
      "Requirement already satisfied: qdrant-client in ./venv/lib/python3.11/site-packages (1.13.2)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (4.67.1)\r\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.11/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: ragas in ./venv/lib/python3.11/site-packages (0.2.12)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in ./venv/lib/python3.11/site-packages (from wikipedia) (2.32.3)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.11/site-packages (from beautifulsoup4) (2.6)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.11/site-packages (from openai) (4.8.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.11/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.11/site-packages (from openai) (0.28.1)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.11/site-packages (from openai) (0.8.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.11/site-packages (from openai) (2.10.6)\r\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.11/site-packages (from openai) (4.12.2)\r\n",
      "Requirement already satisfied: grpcio>=1.41.0 in ./venv/lib/python3.11/site-packages (from qdrant-client) (1.70.0)\r\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in ./venv/lib/python3.11/site-packages (from qdrant-client) (1.70.0)\r\n",
      "Requirement already satisfied: numpy>=1.21 in ./venv/lib/python3.11/site-packages (from qdrant-client) (1.26.4)\r\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in ./venv/lib/python3.11/site-packages (from qdrant-client) (2.10.1)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in ./venv/lib/python3.11/site-packages (from qdrant-client) (2.3.0)\r\n",
      "Requirement already satisfied: datasets in ./venv/lib/python3.11/site-packages (from ragas) (3.2.0)\r\n",
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.11/site-packages (from ragas) (0.8.0)\r\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.11/site-packages (from ragas) (0.3.17)\r\n",
      "Requirement already satisfied: langchain-core in ./venv/lib/python3.11/site-packages (from ragas) (0.3.33)\r\n",
      "Requirement already satisfied: langchain-community in ./venv/lib/python3.11/site-packages (from ragas) (0.3.16)\r\n",
      "Requirement already satisfied: langchain_openai in ./venv/lib/python3.11/site-packages (from ragas) (0.3.3)\r\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.11/site-packages (from ragas) (1.6.0)\r\n",
      "Requirement already satisfied: appdirs in ./venv/lib/python3.11/site-packages (from ragas) (1.4.4)\r\n",
      "Requirement already satisfied: diskcache>=5.6.3 in ./venv/lib/python3.11/site-packages (from ragas) (5.6.3)\r\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\r\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in ./venv/lib/python3.11/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (5.29.3)\r\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.11/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (65.5.0)\r\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: h2<5,>=3 in ./venv/lib/python3.11/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from datasets->ragas) (3.17.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.11/site-packages (from datasets->ragas) (19.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.11/site-packages (from datasets->ragas) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (from datasets->ragas) (2.2.3)\r\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.11/site-packages (from datasets->ragas) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./venv/lib/python3.11/site-packages (from datasets->ragas) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./venv/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->ragas) (2024.9.0)\r\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.11/site-packages (from datasets->ragas) (3.11.11)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./venv/lib/python3.11/site-packages (from datasets->ragas) (0.28.1)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from datasets->ragas) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.11/site-packages (from datasets->ragas) (6.0.2)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.11/site-packages (from langchain->ragas) (2.0.37)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in ./venv/lib/python3.11/site-packages (from langchain->ragas) (0.3.5)\r\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.11/site-packages (from langchain->ragas) (0.3.4)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.11/site-packages (from langchain->ragas) (9.0.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.11/site-packages (from langchain-core->ragas) (1.33)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.11/site-packages (from langchain-community->ragas) (0.6.7)\r\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in ./venv/lib/python3.11/site-packages (from langchain-community->ragas) (0.4.0)\r\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./venv/lib/python3.11/site-packages (from langchain-community->ragas) (2.7.1)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.11/site-packages (from tiktoken->ragas) (2024.11.6)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (2.4.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (25.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (0.2.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (1.18.3)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.0)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\r\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in ./venv/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\r\n",
      "Requirement already satisfied: hpack<5,>=4.1 in ./venv/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (3.10.15)\r\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (1.0.0)\r\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (0.23.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas->datasets->ragas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas->datasets->ragas) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas->datasets->ragas) (2025.1)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wikipedia mwparserfromhell beautifulsoup4 openai qdrant-client tqdm python-dotenv ragas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:57:39.924804Z",
     "start_time": "2025-02-02T13:57:39.920265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:55:51.352112Z",
     "start_time": "2025-02-02T13:55:28.904956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Machine learning\n",
      "Skipping Computer vision\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "import json\n",
    "import re\n",
    "from mwparserfromhell import parse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "ARTICLE_TITLES = [\n",
    "    \"Machine learning\", \"Deep learning\",\n",
    "    \"Transformer (machine learning model)\", \"Natural language processing\",\n",
    "    \"Computer vision\", \"Reinforcement learning\",\n",
    "    \"Artificial neural network\", \"Generative pre-trained transformer\",\n",
    "    \"BERT (language model)\", \"Overfitting\"\n",
    "]\n",
    "\n",
    "def fetch_wikipedia_article(title):\n",
    "    try:\n",
    "        page = wikipedia.page(title)\n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"url\": page.url,\n",
    "            \"raw_content\": page.content\n",
    "        }\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return fetch_wikipedia_article(e.options[0])\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        print(f\"Skipping {title}\")\n",
    "        return None\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove wiki markup and citation numbers\n",
    "    text = ''.join(parse(text).strip_code())\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    return re.sub(r'\\[\\d+\\]', '', text).strip()\n",
    "\n",
    "articles = []\n",
    "for title in ARTICLE_TITLES:\n",
    "    article = fetch_wikipedia_article(title)\n",
    "    if article:\n",
    "        article[\"content\"] = clean_text(article[\"raw_content\"])\n",
    "        articles.append(article)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-02T13:55:51.359207Z",
     "start_time": "2025-02-02T13:55:51.354947Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:55:51.371310Z",
     "start_time": "2025-02-02T13:55:51.360889Z"
    }
   },
   "outputs": [],
   "source": [
    "# Chunking function\n",
    "def chunk_text(text, chunk_size=300, overlap=50):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+chunk_size]) \n",
    "            for i in range(0, len(words), chunk_size - overlap)]\n",
    "\n",
    "# Prepare chunks and metadata\n",
    "corpus = []\n",
    "metadata = []\n",
    "for article in articles:\n",
    "    chunks = chunk_text(article[\"content\"])\n",
    "    corpus.extend(chunks)\n",
    "    metadata.extend([{\"title\": article[\"title\"], \"url\": article[\"url\"]}] * len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(corpus)\n",
    "len(metadata)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Create Embeddings with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:57:52.288614Z",
     "start_time": "2025-02-02T13:57:44.194859Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# Define the embedding function using OpenAI's API (using text-embedding-ada-002)\n",
    "def openai_embedding(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=[text],  # Passing the text as a list\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    # Use dot notation to access the embedding from the response object\n",
    "    embeddings = [data.embedding for data in response.data]\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "embeddings = []\n",
    "chunked_texts = []\n",
    "metadata_chunks = []\n",
    "test_corpus = corpus[:10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for chunk in tqdm(test_corpus):\n",
    "    embedding = openai_embedding(chunk)\n",
    "    embeddings.extend(embedding)\n",
    "    chunked_texts.extend([chunk] * len(embedding))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Indexing with Qdrant Vector Store"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:58:08.243554Z",
     "start_time": "2025-02-02T13:58:06.269315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "\n",
    "# Create an in-memory Qdrant instance\n",
    "client = QdrantClient(\":memory:\")\n",
    "collection_name = \"wikipedia_articles\"\n",
    "\n",
    "# Create the collection with the specified vector configuration\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Upsert points into the collection using PointStruct for each point\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=[\n",
    "        PointStruct(\n",
    "            id=idx,\n",
    "            vector=embedding,\n",
    "            payload={\"text\": chunked_texts[idx]}\n",
    "        )\n",
    "        for idx, embedding in enumerate(embeddings)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Deep learning is a subset of machine learning that focuses on utilizing neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be either supervised, semi-supervised or unsupervised. Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance. Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose. Overview Most modern deep learning models are based on multi-layered neural networks such as convolutional neural networks and transformers, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines. Fundamentally, deep learning refers to a class of machine learning algorithms in which a hierarchy of layers is used to transform input data into a progressively more abstract and composite representation. For example, in an image recognition model, the raw input may be an image (represented as a tensor of pixels). The first representational layer may attempt to identify'}\n"
     ]
    }
   ],
   "source": [
    "# Function to search the database\n",
    "def vector_search(query, top_k=3):\n",
    "\n",
    "  # create embedding of the query\n",
    "  response = openai_client.embeddings.create(\n",
    "      input=query,\n",
    "      model=\"text-embedding-3-small\"\n",
    "  )\n",
    "  query_embeddings = response.data[0].embedding\n",
    "  # similarity search using the embedding, give top n results which are close to the query embeddings\n",
    "  search_result = client.query_points(\n",
    "      collection_name=collection_name,\n",
    "      query=query_embeddings,\n",
    "      with_payload=True,\n",
    "      limit=top_k,\n",
    "  ).points\n",
    "  return [result.payload for result in search_result]\n",
    "\n",
    "search_result = vector_search(\"What is Reinforcement learning?\")\n",
    "print(search_result[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-02T13:58:09.210670Z",
     "start_time": "2025-02-02T13:58:08.245805Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:58:09.219286Z",
     "start_time": "2025-02-02T13:58:09.213586Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_generate(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build the Q/A Chatbot\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def prompt_template(question, context):\n",
    "  return \"\"\"You are a AI Assistant that provides answer to the question at the end, over the following\n",
    "  pieces of context.\n",
    "  context:\n",
    "  ```\n",
    "  \"\"\"+ json.dumps(context) + \"\"\"\n",
    "  ```\n",
    "  User question: \"\"\"+ question +\"\"\"\n",
    "  Answer in markdown:\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-02T13:58:09.948913Z",
     "start_time": "2025-02-02T13:58:09.945212Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Deep learning is a subset of machine learning that utilizes neural networks to perform various tasks such as classification, regression, and representation learning. It is inspired by biological neuroscience and involves stacking artificial neurons into multiple layers, which allows the model to process and learn from data in a hierarchical manner.\n",
      "\n",
      "### Key Features of Deep Learning:\n",
      "\n",
      "- **Multiple Layers**: The term \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the neural network. Each layer transforms the input data into progressively more abstract representations.\n",
      "  \n",
      "- **Automatic Feature Learning**: Unlike traditional machine learning techniques that often require hand-crafted feature engineering, deep learning models automatically discover useful feature representations from the data.\n",
      "\n",
      "- **Types of Networks**: Common architectures include:\n",
      "  - Fully Connected Networks\n",
      "  - Convolutional Neural Networks (CNNs)\n",
      "  - Recurrent Neural Networks (RNNs)\n",
      "  - Generative Adversarial Networks (GANs)\n",
      "  - Transformers\n",
      "\n",
      "- **Applications**: Deep learning has been successfully applied in various fields such as computer vision, speech recognition, natural language processing, and medical image analysis, often achieving results that are comparable to or surpass human expert performance.\n",
      "\n",
      "- **Learning Paradigms**: Deep learning methods can be supervised, semi-supervised, or unsupervised, allowing them to work with both labeled and unlabeled data.\n",
      "\n",
      "- **Credit Assignment Path (CAP)**: The depth of the network, or the number of layers, contributes to the complexity of the model's ability to learn and represent features. A deeper network (with a CAP depth greater than two) can extract better features than shallower models.\n",
      "\n",
      "Overall, deep learning represents a powerful approach to machine learning that leverages the capabilities of neural networks to learn from large amounts of data effectively.\n"
     ]
    }
   ],
   "source": [
    "def generate_answer(question):\n",
    "  #Retrieval: search a knowledge base.\n",
    "  search_result = vector_search(question)\n",
    "\n",
    "  prompt = prompt_template(question, search_result)\n",
    "  # Generation: LLMs' ability to generate the answer\n",
    "  return model_generate(prompt)\n",
    "\n",
    "question = f\"What is deep learning ?\"\n",
    "answer = generate_answer(question)\n",
    "print(\"Answer:\", answer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-02T13:58:14.709480Z",
     "start_time": "2025-02-02T13:58:11.076986Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
